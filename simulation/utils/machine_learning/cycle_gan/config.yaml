base:
  activation: TANH # Choose which activation to use. [TANH | HARDTANH | SELU | CELU | SOFTSHRINK | SOFTSIGN]
  checkpoints_dir: ./checkpoints #models are saved here
  conv_layers_in_block: 2 #specify number of convolution layers per resnet block
  crop_size: 256 #then crop to this size
  dilations: [1,2] #dilation for individual conv layers in every resnet block
  epoch: latest #which epoch to load? set to latest to use latest cached model
  gpu_ids: [0] #gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU
  init_gain: 0.02 #scaling factor for normal, xavier and orthogonal.
  init_type: normal #network initialization [normal | xavier | kaiming | orthogonal]
  input_nc: 1 # # of input image channels: 3 for RGB and 1 for grayscale
  lambda_a: 10.0 #weight for loss of domain A
  lambda_b: 10.0 #weight for loss of domain B
  lambda_identity: 0.5 #weight for loss identity
  load_iter: 0 #which iteration to load? if load_iter > 0, the code will load models by iter_[load_iter]; otherwise, the code will load models by [epoch]
  load_size: 256 #scale images to this size
  mask: resources/mask.png #Path to a mask overlaid over all images
  n_layers_d: 3 #number of layers in the discriminator network
  name: dr_drift_256 #name of the experiment. It decides where to store samples and models
  ndf: 32 # # of discriminator filters in the first conv layer
  netd: basic #specify discriminator architecture [basic | n_layers | no_patch]. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator
  netg: resnet_9blocks #specify generator architecture [resnet_<ANY_INTEGER>blocks | unet_256 | unet_128]
  ngf: 32 # # of gen filters in the last conv layer
  no_dropout: True #no dropout for the generator
  norm: instance #instance normalization or batch normalization [instance | batch | none]
  output_nc: 1 # # of output image channels: 3 for RGB and 1 for grayscale
  preprocess: resize_and_crop #scaling and cropping of images at load time [resize_and_crop | crop | scale_width | scale_width_and_crop | none]
  suffix: #customized suffix: opt.name = opt.name + suffix: e.g., {model}_{netg}_size{load_size}
  verbose: False #if specified, print more debugging information
  cycle_noise_stddev: 0 #Standard deviation of noise added to the cycle input. Mean is 0.
  use_sigmoid: False #Use sigmoid activation at the end of discriminator network
  pool_size: 75 #the size of image buffer that stores previously generated images
  gan_mode: lsgan #the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.
  max_dataset_size: -1 #maximum amount of images to load; -1 means infinity
train:
  dataset_a:  #path to images of domain A (real images). Can be a list of folders
    - ./../../../../data/real_images/maschinen_halle
    - ./../../../../data/real_images/maschinen_halle_no_obstacles
  dataset_b: #path to images of domain B (simulated images). Can be a list of folders
    - ./../../../../data/simulated_images/random_roads
  display_env: main #visdom display environment name (default is "main")
  display_freq: 5 #frequency of showing training results on screen
    # - ./../../../../data/real_images/maschinen_halle_parking
  display_id: 1 #window id of the web display
  display_port: 8097 #visdom port of the web display
  epoch_count: 1 #the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...
  is_train: True # enable or disable training mode
  num_threads: 8 # # threads for loading data
  print_freq: 100 #frequency of showing training results on console
  save_by_iter: False #whether saves model by iteration
  save_epoch_freq: 1 #frequency of saving checkpoints at the end of epochs
  save_latest_freq: 1000 #frequency of saving the latest results
  beta1: 0.5 #momentum term of adam
  batch_size: 8 #input batch size
  lr: 0.0005 #initial learning rate for adam
  lr_decay_iters: 1 #multiply by a gamma every lr_decay_iters iterations
  lr_policy: step #learning rate policy. [linear | step | plateau | cosine]
  lr_step_factor: 0.5  # Multiplication factor at every step in the step scheduler
  continue_train: False #continue training: load the latest model
  n_epochs: 10 # number of epochs with the initial learning rate
  n_epochs_decay: 0 #number of epochs to linearly decay learning rate to zero
  no_flip: False  # Flip 50% of all training images vertically
test:
  dataset_a:  #path to images of domain A (real images). Can be a list of folders
    - ./../../../../data/real_images/maschinen_halle_parking
  dataset_b: #path to images of domain B (simulated images). Can be a list of folders
    - ./../../../../data/simulated_images/complex_road
  results_dir: ./results/ #saves results here.
  aspect_ratio: 1 #aspect ratio of result images
  is_train: False # enable or disable training mode
