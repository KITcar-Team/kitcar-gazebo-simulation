{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import os\n",
    "import nn.classifier\n",
    "import nn.unet as unet\n",
    "import img.dataset as ds\n",
    "from img import transformer\n",
    "import color_classes as cc\n",
    "    \n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "\n",
    "from nn.train_callbacks import TensorboardVisualizerCallback, TensorboardLoggerCallback, ModelSaverCallback\n",
    "from nn.test_callbacks import PredictionsSaverCallback\n",
    "import helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nn.test_callbacks' from '/home/ditschuk/kitcar/kitcar-gazebo-generation/segmentation/nn/test_callbacks.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(nn.unet)\n",
    "importlib.reload(cc)\n",
    "importlib.reload(transformer)\n",
    "importlib.reload(ds)\n",
    "importlib.reload(nn.classifier)\n",
    "importlib.reload(nn.test_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "    img_resize = (320, 160)\n",
    "    batch_size = 1\n",
    "    epochs = 3\n",
    "    threshold = 0.5\n",
    "    validation_size = 0.2\n",
    "    sample_size = None  # Put None to work on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.environ.get('KITCAR_GAZEBO_SIM_PATH') + '/datasets/segmentation/'\n",
    "train_folder = data_folder + 'train'\n",
    "test_folder = data_folder + 'test'\n",
    "labels_folder = data_folder + 'train_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_img_name = os.listdir(train_folder)[100]\n",
    "ex_img = cv2.imread(os.path.join(train_folder,ex_img_name))\n",
    "ex_label_img = cv2.imread(os.path.join(labels_folder,ex_img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = unet.UNet1024((3, 160,320))\n",
    "classifier = nn.classifier.CarvanaClassifier(net, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds.SegmentationImageDataset(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img.dataset import SegmentationImageDataset\n",
    "from multiprocessing import cpu_count\n",
    "threads = cpu_count()\n",
    "use_cuda=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size,\n",
    "                              sampler=RandomSampler(train_ds),\n",
    "                              num_workers=threads,\n",
    "                              pin_memory=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = ds.SegmentationImageDataset(data_folder, train_folder='validate')\n",
    "valid_loader = DataLoader(valid_ds, batch_size,\n",
    "                              sampler=SequentialSampler(valid_ds),\n",
    "                              num_workers=threads,\n",
    "                              pin_memory=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 319 samples and validating on 16 samples \n"
     ]
    }
   ],
   "source": [
    "print(\"Training on {} samples and validating on {} samples \"\n",
    "          .format(len(train_loader.dataset), len(valid_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_viz_cb = TensorboardVisualizerCallback(os.path.join(data_folder, 'logs/tb_viz'))\n",
    "tb_logs_cb = TensorboardLoggerCallback(os.path.join(data_folder, 'logs/tb_logs'))\n",
    "model_saver_cb = ModelSaverCallback(os.path.join(data_folder, 'output/models/model_' +\n",
    "                                                     helpers.get_model_timestamp()), verbose=True)\n",
    "# Testing callbacks\n",
    "pred_saver_cb = PredictionsSaverCallback(os.path.join(data_folder, 'output/submit.csv.gz'),\n",
    "                                             [1280,650], threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 1/3:   0%|          | 0/319 [?]/home/ditschuk/.local/lib/python3.6/site-packages/torch/nn/functional.py:2390: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/ditschuk/.local/lib/python3.6/site-packages/torch/nn/functional.py:2479: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/ditschuk/.local/lib/python3.6/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/ditschuk/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epochs 1/3: 100%|██████████| 319/319 [00:00, loss=0.09186, dice_coeff=0.98899]\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]/home/ditschuk/kitcar/kitcar-gazebo-generation/segmentation/nn/classifier.py:59: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  images = Variable(images, volatile=True)\n",
      "/home/ditschuk/kitcar/kitcar-gazebo-generation/segmentation/nn/classifier.py:60: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  targets = Variable(targets, volatile=True)\n",
      "Epochs 2/3:   0%|          | 0/319 [?]                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss = 0.492840, train_acc = 0.929337\n",
      "val_loss   = 0.095230, val_acc   = 0.983684\n",
      "Time elapsed = 401s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 2/3: 100%|██████████| 319/319 [00:00, loss=0.02453, dice_coeff=0.99527]\n",
      "Epochs 3/3:   0%|          | 0/319 [?]                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss = 0.053225, train_acc = 0.989890\n",
      "val_loss   = 0.040612, val_acc   = 0.987381\n",
      "Time elapsed = 396s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 3/3: 100%|██████████| 319/319 [00:00, loss=0.01393, dice_coeff=0.99709]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss = 0.025237, train_acc = 0.992932\n",
      "val_loss   = 0.024142, val_acc   = 0.991942\n",
      "Time elapsed = 396s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "classifier.train(train_loader, valid_loader, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ds.SegmentationImageDataset(data_folder, train_folder='validate')\n",
    "test_loader = DataLoader(test_ds, batch_size,\n",
    "                             sampler=SequentialSampler(test_ds),\n",
    "                             num_workers=threads,\n",
    "                             pin_memory=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2a93a54b9ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mex_img_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mex_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mex_img_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mex_label_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mex_img_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter_cropping_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "ex_img_name = os.listdir(test_folder)[2]\n",
    "ex_img = cv2.imread(os.path.join(test_folder,ex_img_name))\n",
    "ex_label_img = cv2.imread(os.path.join(labels_folder,ex_img_name))\n",
    "cropped = transformer.center_cropping_resize(ex_img,[320,160])\n",
    "t = torch.from_numpy(cropped.transpose(2,0,1)).float().unsqueeze(0)\n",
    "res = net(t)[0][1].detach()\n",
    "plt.subplot(221)\n",
    "plt.imshow(cropped)\n",
    "plt.title('Image')\n",
    "plt.subplot(222)\n",
    "plt.imshow(ex_label_img)\n",
    "plt.title('Label')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(res)\n",
    "plt.title('Result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
